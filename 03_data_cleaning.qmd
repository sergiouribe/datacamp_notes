---
title: "03_data_cleaning"
format: html
editor: visual
---

```{r}
pacman::p_load(tidyverse,
               tibble, 
               janitor, 
               reclin2 ) # for record linkage) 
```

# **Detecting inconsistent text data**

```{r}
# Filter for rows with "-" in the phone column
sfo_survey %>%
  filter(str_detect(phone, "-"))
```

```{r}
# Filter for rows with "(" or ")" in the phone column
sfo_survey %>%
  filter(str_detect(phone, fixed("(")) | str_detect(phone, fixed(")")))
```

# **Replacing and removing**

```{r}
# Remove parentheses from phone column
phone_no_parens <- sfo_survey$phone %>%
  # Remove "("s
  str_remove_all(fixed("(")) %>%
  # Remove ")"s
  str_remove_all(fixed(")"))
```

```{r}
nyc_temps <-  
  read_delim("https://raw.githubusercontent.com/corytophanes/BIO_BIT_Bioinformatics_209/refs/heads/main/ref_files_pdfs/nyc_temps.txt")
```

```{r}
glimpse(nyc_temps)
```

```{r}
nyc_temps_long <- nyc_temps %>%
  pivot_longer(
    cols = -YEAR,  # Keep YEAR as identifier
    names_to = "MONTH",  # Create a column for months
    values_to = "TEMPERATURE"  # Store temperatures in this column
  )  |> 
 mutate(MONTH = match(MONTH, toupper(month.abb)),  # Convert month abbreviation to numeric
         DATE = as.Date(paste(YEAR, MONTH, "01", sep = "-")))  # Merge YEAR and MONTH into a date
         




```

```{r}
nyc_temps_long |> 
  
  # filter(MONTH != NA) |> 
  ggplot(aes(x = as.factor(MONTH), y = TEMPERATURE, color = YEAR)) +
  geom_jitter(alpha = .5) +
  labs(
    title = "Temperature Variations by Month",
    x = "Month",
    y = "Temperature (Â°C)",
    color = "Year"
  )
```

```{r}
nyc_temps_long |> 
  tabyl(MONTH)
  
```

# Dates

```{r}
# Check out the accounts data frame
head(accounts)

# Define the date formats
formats <- c("%Y-%m-%d", "%B %d, %Y")

# Convert dates to the same format
accounts %>%
  mutate(date_opened_clean = parse_date_time(date_opened, formats))
```

```{r}
# convert yen to usd
accounts %>%
  mutate(total_usd = ifelse(total > 1000000, total / 104, total))
```

# Missing Values

```{r}
pacman::p_load(tidyverse, 
               visdat)
```

```{r}
data("airquality")
```

```{r}
sum(is.na(airquality))
```

```{r}
visdat::vis_miss(airquality)
```

```{r}
airquality |> 
  mutate(miss_ozone = is.na(Ozone)) |> 
  group_by(miss_ozone) |> 
  summarize(across(everything(), median, na.rm = T))
```

```{r}
airquality |> 
  arrange(desc(Ozone)) |> 
  vis_miss()
```

![](images/clipboard-560287637.png)

# Comparing strings

## Types of edit distance

![](images/clipboard-454113606.png)

```{r}
pacman::p_load(stringdist)
```

```{r}
stringdist::stringdist("baboon", 
                       "typhoon", 
                       method = "dl")
```

```{r}
# LCS
stringdist::stringdist("baboon", 
                       "typhoon", 
                       method = "lcs")
```

```{r}
# jaccard
stringdist::stringdist("baboon", 
                       "typhoon", 
                       method = "jaccard")
```

## fussyjoin

```{r}
pacman::p_load(fuzzyjoin)
```

![](images/clipboard-466977798.png)

![](images/clipboard-672267679.png)

# Record linkage

-   **Record Linkage Basics**: You discovered that record linkage involves cleaning datasets, generating pairs of records to compare, scoring these pairs based on similarity, and finally linking the most similar pairs.

-   **Generating Pairs**: Using the `reclin2` package in R, you learned how to generate all possible pairs of records between two data frames. You saw firsthand how this could lead to a large number of comparisons, making the process inefficient for large datasets.

-   **Blocking to Reduce Comparisons**: To make the process more scalable, you applied the concept of blocking. By only generating pairs that match on a specified blocking variable (e.g., the state column), you significantly reduced the number of pairs to compare. This was achieved with the `pair_blocking` function, specifying the `blocking_var` argument.

-   **Comparing Pairs**: You explored how to compare pairs of records by using the `compare_pairs` function from the `reclin2` package. You learned to specify which columns to compare and how to compare them using different string comparison methods, such as the longest common subsequence (LCS) method. For example:

```         
pairs %>% compare_pairs(by = "name", default_comparator = lcs())
```

![](images/clipboard-231128390.png)

```{r}
pacman::p_load(reclin2)
```

![](images/clipboard-1333049409.png)

Read <https://cran.r-project.org/web/packages/reclin2/vignettes/introduction.html>

```{r}
data("linkexample1", "linkexample2")
```

```{r}
print(linkexample1)
```

```{r}
print(linkexample2)
```

### Step 1 Generate pairs

```{r}
 pairs <- pair_blocking(linkexample1, linkexample2, "postcode")
 print(pairs)
```

### **Step 2: compare pairs**

```{r}
pairs <- compare_pairs(pairs, on = c("lastname", "firstname", "address", "sex"))
```

```{r}
print(pairs)
```

```{r}

# Generate pairs
pairs |> 
  # Compare pairs by name, phone, addr
  compare_pairs(on = c("lastname", "postcode", "address"),
                       default_comparator = cmp_jaccard(threshold = 0.5)  )
```

## **Scoring and linking**

![![](images/clipboard-3103731353.png)](images/clipboard-3552853818.png)

![](images/clipboard-4265653364.png)

![](images/clipboard-2604538815.png)

But several issues: sex is a good match, but useless

So,

![Then link](images/clipboard-529695242.png)

![](images/clipboard-1183508693.png)

![](images/clipboard-1824191539.png)

![](images/clipboard-1472979257.png)

## How to 

1.  clean the datasets
2.  generate pair or records
3.  compare separate columns of each pair
4.  score pairs using summing or probability
5.  select pairs that are matches based on their score
6.  link the datasets together

```{r}
# Create example datasets (if needed)
dat1 <- tibble(
  id = 1:5,
  first_name = c("John", "Jane", "Alice", "Robert", "Charlie"),
  last_name = c("Doe", "Doe", "Brown", "Smith", "Adams"),
  birth_year = c(1980, 1992, 1985, 1978, 1990)
)

dat2 <- tibble(
  id = 6:10,
  first_name = c("Jon", "Janet", "Alicia", "Rob", "Charles"),
  last_name = c("Doe", "Doe", "Browne", "Smyth", "Adams"),
  birth_year = c(1980, 1992, 1985, 1978, 1990)
)

```

```{r}
head(dat1)
```

```{r}
head(dat2)
```

```{r}
# Clean datasets (convert to lowercase, remove whitespace, etc.)
clean_data <- function(df) {
  df |> mutate(
    first_name = tolower(trimws(first_name)),
    last_name = tolower(trimws(last_name))
  )
}

dat1 <- clean_data(dat1)
dat2 <- clean_data(dat2)
```

```{r}




# Generate pairs of records
pairs <- pair_blocking(dat1, dat2, on = "birth_year")

# Compare separate columns of each pair using Jaro-Winkler similarity
compare_pairs(pairs, on = c("last_name", "first_name"), 
              default_comparator = cmp_jarowinkler(0.9), inplace = TRUE)

# Estimate probabilistic linkage parameters using the EM algorithm
m <- problink_em(~ last_name + first_name, data = pairs)
print(m)  # Display estimated m- and u-probabilities

# Predict match probabilities and add to pairs
pairs <- predict(m, pairs = pairs, add = TRUE)

# Score pairs using a simple weighted sum method
pairs <- score_simple(pairs, "score", 
                      on = c("last_name", "first_name"), 
                      w1 = c(last_name = 2, first_name = 1), 
                      w0 = -1, wna = 0)

# Select pairs based on a threshold
pairs <- select_threshold(pairs, "threshold", score = "score", threshold = 1.5)

# Enforce one-to-one matching using a greedy selection approach
pairs <- select_greedy(pairs, "score", variable = "greedy", threshold = 1.5)

# Link datasets together based on selected pairs
linked_data <- link(pairs, selection = "greedy")

# Display linked dataset
print(linked_data)

```

# SUMMARY

![](images/clipboard-1032426442.png)

![](images/clipboard-2876810608.png)

![![](images/clipboard-1457813890.png)![](images/clipboard-1950458036.png)](images/clipboard-27555222.png)
