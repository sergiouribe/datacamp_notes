---
title: "09_sampling"
format: html
editor: visual
---

```{r}
pacman::p_load(tidyverse)
```

```{r}
# Take a random sample of 100 penguins
penguins_sample <- penguins %>%
  slice_sample(n = 100)

# Calculate the mean body mass (in kg) from the full population
mean_mass_pop <- penguins %>%
  summarise(mean_body_mass_kg = mean(body_mass, na.rm = TRUE) / 1000)

# Calculate the mean body mass (in kg) from the sample
mean_mass_samp <- penguins_sample %>%
  summarise(mean_body_mass_kg = mean(body_mass, na.rm = TRUE) / 1000)

# See the results
mean_mass_pop

```

```{r}
mean_mass_samp
```

```{r}
# rm(mean_mass_pop, mean_mass_samp)
```

```{r}
penguins |> 
  select(body_mass) |> 
  slice_sample(n = 100) |> 
  summarise(mean(body_mass, na.rm = T))
```

```{r}
penguins |> 
  select(body_mass) |> 
  slice_sample(n = 100) |> 
  summarise(sd(body_mass, na.rm = T))
```

```{r}
penguins |> 
  select(body_mass) |> 
  slice_sample(n = 10) |> 
  summarise(mean(body_mass, na.rm = T))
```

```{r}
penguins |> 
  select(body_mass) |> 
  slice_sample(n = 10) |> 
  summarise(sd(body_mass, na.rm = T))
```

```{r}
penguins |> 
  select(body_mass) |> 
  slice_sample(n = 300) |> 
  ggplot(aes(x = body_mass)) + 
  geom_histogram(binwidth = 200) +
  geom_vline(aes(xintercept = mean(body_mass, na.rm = TRUE)), 
             color = "black", linetype = "dashed", linewidth = 1) +
  labs(title = "Histogram of Body Mass (g) with Mean Line")
```

```{r}
penguins |> 
  select(body_mass) |> 
  slice_sample(n = 30) |> 
  ggplot(aes(x = body_mass)) + 
  geom_histogram(binwidth = 200) +
  geom_vline(aes(xintercept = mean(body_mass, na.rm = TRUE)), 
             color = "black", linetype = "dashed", linewidth = 1) +
  labs(title = "Histogram of Body Mass (g) with Mean Line")
```

## Random numbers

```{r}
# Generate random numbers from ...
randoms <- data.frame(
  # a uniform distribution from -3 to 3
  uniform = runif(5000, min = -3, max =  3),
  # a normal distribution with mean 5 and sd 2
  normal = rnorm(5000, mean = 5, sd = 2)
)
```

```{r}
randoms |>
  pivot_longer(uniform:normal) |> 
  ggplot(aes(x = value, 
             fill = name)) + 
  geom_histogram()  + 
  facet_grid(name ~.) + 
  theme(legend.position = "none")
```

```{r}
set.seed(123)
x <- c(rnorm(5), rnorm(5))
set.seed(123)
y <- rnorm(10)
```

## RECAP

-   **Pseudo-random vs. True Randomness**: True randomness relies on physical processes, such as radioactive decay or atmospheric noise. Pseudo-random numbers, however, are generated algorithmically, based on a seed value, making them faster and more practical for most applications.

-   **Seed Value and Reproducibility**: The seed value initiates the pseudo-random number generation process. By setting a specific seed value using `set.seed()`, you ensure that the same sequence of numbers is generated every time, which is crucial for reproducibility in scientific research and data analysis.

-   **Generating Pseudo-random Numbers in R**: You explored functions like `rnorm()` for generating numbers from a normal distribution. For example, `rnorm(5)` generates five pseudo-random numbers from a normal distribution.

-   **Visualizing Distributions**: Using `ggplot2`, you learned how to visualize the distribution of pseudo-random numbers, enhancing your understanding of statistical distributions and their properties.

Example

```{r}
# Shuffle the rows of penguins and add row IDs
penguins_shuffled <- penguins %>%
  slice_sample(prop = 1) %>%
  rowid_to_column()

# Plot body_mass_g vs. rowid
ggplot(penguins_shuffled, aes(rowid, body_mass)) +
  geom_point() +
  geom_smooth()
```

## Stratified and weigthed random sampling

Tip: using semijoins to filter:

![](images/clipboard-3392166877.png)

![](images/clipboard-3592010481.png)

![](images/clipboard-1165298139.png)

```{r}
# Count number of penguins by species and calculate percent
penguins %>% 
  count(species, sort = TRUE) %>% 
  mutate(percent = 100 * n / sum(n))
```

```{r}
# Use proportional stratified sampling to get 40% of each species group
penguins_strat <- penguins %>% 
  group_by(species) %>% 
  slice_sample(prop = 0.4) %>% 
  ungroup()
```

```{r}
penguins_strat
```

```{r}
# Summarize original penguins dataset
penguins_summary <- penguins %>%
  count(species, island) %>%
  mutate(percent_full = 100 * n / sum(n)) %>%
  select(-n)

# Summarize stratified sample
penguins_strat_summary <- penguins_strat %>%
  count(species, island) %>%
  mutate(percent_strat = 100 * n / sum(n)) %>%
  select(-n)

# Join the two summaries side-by-side
penguins_summary %>%
  full_join(penguins_strat_summary, by = c("species", "island")) |> 
  mutate(diff = percent_full - percent_strat ) |> 
  mutate_if(is.numeric, ~ round(., 1))


```

## recap 2

**Simple Random Sampling** is akin to a lottery draw, where each member of the population has an equal chance of being selected. This method ensures that every possible sample has the same probability of being chosen. You saw how to implement this in R using the slice_sample function, where n specifies the number of items to sample from the dataset.

**Systematic Sampling** involves selecting members from a larger population according to a random starting point and a fixed, periodic interval. This method is useful when dealing with large datasets and provides a simple alternative to random sampling. However, it can introduce bias if the population is not homogeneous. The key steps in R include adding a row ID column with rowid_to_column and then using arithmetic to select rows at regular intervals. For example, to sample every 267th row from a dataset, you could use:

```{r}
penguins_samp <- penguins %>%
  rowid_to_column() %>%
  slice((1:5) * 5)  # Example: pick every 5th row (adjust the number to match your case)
```

```{r}
head(penguins_samp)
```

## Weigthed sample

```{r}
# Sample 400 employees weighted by Island
penguins_weight <- penguins %>%
group_by(island) %>%
slice_sample(n = 60)

penguins_weight
```

COmpare

```{r}
penguins |> 
  ggplot(aes(x = island, y = body_mass, fill = island)) + 
  geom_violin() + 
  geom_boxplot(alpha = 0.5, width = 0.2) + 
  geom_jitter(alpha = .10, width = 0.2) + 
  facet_wrap(~species)
```

```{r}
penguins_weight |> 
  ggplot(aes(x = island, y = body_mass, fill = island)) + 
  geom_violin() + 
  geom_boxplot(alpha = 0.5, width = 0.2) + 
  geom_jitter(alpha = .10, width = 0.2)  + 
  facet_wrap(~species)
```

```{r}
 penguins |> 
   slice_sample(n = 400, weight_by = island) |> 
     ggplot(aes(x = island, y = body_mass, fill = island)) + 
  geom_violin() + 
  geom_boxplot(alpha = 0.5, width = 0.2) + 
  geom_jitter(alpha = .10, width = 0.2)  + 
  facet_wrap(~species)
```

```{r}
 # 1. Original dataset: mean body_mass by species
penguins_summary_full <- penguins %>%
  group_by(species) %>%
  summarize(mean_body_mass_full = mean(body_mass, na.rm = TRUE))

# 2. Sample of 60 rows (simple random sampling)
penguins_sample_60 <- penguins %>%
  slice_sample(n = 60)

penguins_summary_sample_60 <- penguins_sample_60 %>%
  group_by(species) %>%
  summarize(mean_body_mass_sample_60 = mean(body_mass, na.rm = TRUE))

# 3. Weighted sample (more weight to heavier penguins)
penguins_with_weights <- penguins %>%
  filter(!is.na(body_mass)) %>%
  mutate(weight = body_mass / sum(body_mass))

penguins_sample_weighted <- penguins_with_weights %>%
  slice_sample(n = 60, weight_by = weight)

penguins_summary_sample_weighted <- penguins_sample_weighted %>%
  group_by(species) %>%
  summarize(mean_body_mass_weighted = mean(body_mass, na.rm = TRUE))

penguins_summary_all <- penguins_summary_full %>%
  left_join(penguins_summary_sample_60, by = "species") %>%
  left_join(penguins_summary_sample_weighted, by = "species") %>%
  mutate_if(is.numeric, ~ round(., 1))

# 5. View the combined table
penguins_summary_all


```

```{r}
# 1. Original full dataset
penguins_full <- penguins %>%
  mutate(sample_type = "Full Dataset")

# 2. Random sample of 60 penguins
penguins_sample_60 <- penguins %>%
  slice_sample(n = 60) %>%
  mutate(sample_type = "Random Sample (60)")

# 3. Weighted sample of 60 penguins
penguins_with_weights <- penguins %>%
  filter(!is.na(body_mass)) %>%
  mutate(weight = body_mass / sum(body_mass))

penguins_sample_weighted <- penguins_with_weights %>%
  slice_sample(n = 60, weight_by = weight) %>%
  mutate(sample_type = "Weighted Sample (60)")

# 4. Combine all datasets
penguins_all <- bind_rows(
  penguins_full,
  penguins_sample_60,
  penguins_sample_weighted
)

# 5. Create the violin plot
penguins_all %>%
  filter(!is.na(body_mass)) %>%
  ggplot(aes(x = species, y = body_mass, fill = sample_type)) +
  geom_violin(position = position_dodge(width = 0.8), trim = FALSE) +
  geom_boxplot(alpha = 0.5) + 
  labs(
    title = "Distribution of Body Mass by Species and Sampling Method",
    x = "Species",
    y = "Body Mass (g)",
    fill = "Sample Type"
  ) +
  theme_minimal()
```

## Cluster sampling

The main benefit of cluster sampling over stratified sampling is that you can save time or money by not including every subgroup in your sample.

![](images/clipboard-2895803311.png)

![](images/clipboard-2237486178.png)

![![](images/clipboard-2464283811.png)](images/clipboard-2503248034.png)

Exercise:

```{r}
# From previous step
# job_roles_pop <- unique(attrition_pop$JobRole)
# job_roles_samp <- sample(job_roles_pop, size = 4)

# Filter for rows where JobRole is in job_roles_samp
# attrition_filtered <- attrition_pop %>% 
#  filter(JobRole %in% job_roles_samp)


# Randomly sample 10 employees from each sampled job role
# attrition_clus <- attrition_filtered %>% 
#  group_by(JobRole) %>% 
#  slice_sample(n = 10)



# See the result
# attrition_clus
```

# **Comparing sampling methods**

![![](images/clipboard-2267552969.png)](images/clipboard-106214084.png)

```{r}
# Define "top" islands to simulate top countries
top_islands <- c("Biscoe", "Dream", "Torgersen")

# Filter the main dataset
penguins_top <- penguins %>%
  filter(island %in% top_islands, !is.na(body_mass))
```

```{r}
# simple
penguins_srs <- penguins_top %>%
  slice_sample(prop = 1/3)
```

```{r}
# str
penguins_strat <- penguins_top %>%
  group_by(species) %>%
  slice_sample(prop = 1/3) %>%
  ungroup()
```

```{r}
# Sample 2 islands
island_samp <- sample(top_islands, size = 2)

penguins_clust <- penguins_top %>%
  filter(island %in% island_samp) %>%
  group_by(island) %>%
  slice_sample(n = floor(nrow(penguins_top) / 6)) %>%
  ungroup()
```

```{r}
# Plot all three sample types in one go
bind_rows(
  # Simple random sample
  penguins %>%
    filter(island %in% c("Biscoe", "Dream", "Torgersen"), !is.na(body_mass)) %>%
    slice_sample(prop = 1/3) %>%
    mutate(sample_type = "Simple Random"),

  # Stratified sample by species
  penguins %>%
    filter(island %in% c("Biscoe", "Dream", "Torgersen"), !is.na(body_mass)) %>%
    group_by(species) %>%
    slice_sample(prop = 1/3) %>%
    ungroup() %>%
    mutate(sample_type = "Stratified"),

  # Cluster sample: 2 random islands, then sample
  {
    selected_islands <- sample(c("Biscoe", "Dream", "Torgersen"), size = 2)
    penguins %>%
      filter(island %in% selected_islands, !is.na(body_mass)) %>%
      group_by(island) %>%
      slice_sample(n = floor(nrow(penguins) / 6)) %>%
      ungroup() %>%
      mutate(sample_type = "Cluster")
  }
) %>%
  ggplot(aes(x = species, y = body_mass, fill = sample_type)) +
  geom_violin(position = position_dodge(width = 0.8), trim = FALSE) +
  labs(
    title = "Comparison of Sampling Techniques on Penguin Body Mass",
    x = "Species",
    y = "Body Mass (g)",
    fill = "Sample Type"
  ) +
  theme_minimal()
```

### Cluster sampling penguins

```{r}
# Get unique values of island (used as clusters)
island_unique <- unique(penguins$island)

# Randomly sample 2 of the unique islands
island_samp <- sample(island_unique, size = 2)

# Perform cluster sampling from those islands, sampling 25% of the full dataset
penguins_clust <- penguins %>%
  filter(island %in% island_samp) %>%
  group_by(island) %>%
  slice_sample(n = floor(nrow(penguins) / 4)) %>%
  ungroup()
```

```{r}
bind_rows(
  penguins %>%
    filter(!is.na(body_mass)) %>%
    mutate(sample_type = "Full"),
  
  penguins_clust %>%
    filter(!is.na(body_mass)) %>%
    mutate(sample_type = "Cluster Sample")
) %>%
  group_by(sample_type, species) %>%
  summarize(mean_body_mass = round(mean(body_mass), 1), .groups = "drop") %>%
  arrange(sample_type, species)
```

```{r}
bind_rows(
  penguins %>%
    filter(!is.na(body_mass)) %>%
    mutate(sample_type = "Full"),

  penguins_clust %>%
    filter(!is.na(body_mass)) %>%
    mutate(sample_type = "Cluster Sample")
) %>%
  ggplot(aes(x = species, y = body_mass, fill = sample_type)) +
  geom_violin(position = position_dodge(width = 0.8), alpha = 0.6, trim = FALSE) +
  geom_jitter(aes(color = sample_type), position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8), size = 1.5, alpha = 0.6) +
  geom_boxplot(alpha = 0.2, width = 0.2) +
  labs(
    title = "Comparison of Penguin Body Mass by Species and Sample Type",
    x = "Species",
    y = "Body Mass (g)",
    fill = "Sample Type",
    color = "Sample Type"
  ) +
  theme_minimal()

```

## Replication

![](images/clipboard-2577322698.png)

![![](images/clipboard-278281891.png)](images/clipboard-2221537491.png)

![](images/clipboard-2458499409.png)

![![](images/clipboard-1678921283.png)](images/clipboard-2271051387.png)

![](images/clipboard-1697713454.png)

![](images/clipboard-3252990925.png)

![](images/clipboard-1190636630.png)

```{r}
# Replicate this code 500 times
mean_attritions <- replicate(
  n = 500, 
  expr = attrition_pop %>% 
    slice_sample(n = 20) %>% 
    summarize(mean_attrition = mean(Attrition == "Yes")) %>% 
    pull(mean_attrition))


# See the result
head(mean_attritions)
```

```{r}
# From previous step
mean_attritions <- replicate(
  n = 500,
  attrition_pop %>% 
    slice_sample(n = 20) %>% 
    summarize(mean_attrition = mean(Attrition == "Yes")) %>% 
    pull(mean_attrition)
)

# Store mean_attritions in a tibble in a column named sample_mean
sample_means <- tibble(sample_mean = mean_attritions)

# Plot a histogram of the `sample_mean` column, binwidth 0.05
sample_means %>% 
  ggplot(aes(x = sample_mean)) +  # <- this must match the column name!
  geom_histogram(binwidth = 0.05) +
  labs(
    title = "Sampling Distribution of Attrition Proportion",
    x = "Sample Mean (Attrition == Yes)",
    y = "Count"
  ) +
  theme_minimal()
```

```{r}
# From previous step
dice <- expand_grid(
  die1 = 1:8,
  die2 = 1:8,
  die3 = 1:8,
  die4 = 1:8,
  die5 = 1:8
) %>% 
  mutate(mean_roll = (die1 + die2 + die3 + die4 + die5) / 5)

# Using dice, draw a bar plot of mean_roll as a factor
ggplot(dice, aes(factor(mean_roll))) + geom_bar()

```

# Central Theorem Limit

-   The difference between exact and approximate sampling distributions. Exact sampling distributions account for every possible outcome of an experiment, while approximate sampling distributions use simulations to estimate these outcomes.

-   Generating all possible combinations of dice rolls to understand exact sampling distributions. For example, with four six-sided dice, there are (6\^4) possible outcomes.

-   Using the `tidyr` package to create these combinations and the `ggplot2` package to visualize the distribution of the mean rolls.

-   The computational challenge of calculating exact sampling distributions for large datasets, necessitating the use of approximations.

-   Simulating approximate sampling distributions by repeating a procedure multiple times. This involves using the `sample` function with `replace = TRUE` and the `replicate` function to generate many sample means.

For instance, to generate a sample mean of four dice rolls and replicate this process a thousand times, you wrapped the expression in braces and stored the results in a tibble for visualization:

```         
replicate(1000, expr = {
  sample_mean <- mean(sample(1:6, size = 4, replace = TRUE))
})
```

-   **Sampling Distributions:** You learned that a sampling distribution represents the distribution of a statistic (like the mean) across multiple samples from the same population.

-   **Central Limit Theorem:** The CLT states that the distribution of sample means approaches a normal distribution as the sample size increases, regardless of the population's distribution. This was illustrated through histograms showing how the distribution becomes more bell-shaped and narrower with larger sample sizes.

-   **Standard Errors:** You discovered that the standard deviation of the sampling distribution (standard error) decreases as the sample size increases. This concept was demonstrated with the formula for estimating the standard deviation of the sampling distribution: the population standard deviation divided by the square root of the sample size.

-   **Mean of Sampling Distributions:** The lesson showed that the mean of a sampling distribution is close to the population mean, reinforcing the accuracy of sampling as a method for estimating population parameters.

An example code snippet from the lesson:

```         
mean(sampling_distribution_50)
```

This code calculates the mean of the sample means from a sampling distribution with a sample size of 50, demonstrating how sample statistics can estimate population parameter

## Bootstrapping

![](images/clipboard-4237702250.png)

![![](images/clipboard-1335555381.png)](images/clipboard-2088987679.png)

The bootstrapping workflow is to generate a resample of the same size as the population, calculate a summary statistic, then repeat this to get a distribution of summary statistics.

The key to deciding whether to sample without or with replacement is whether or not your dataset is best thought of as being the whole population or not.
